# AI-Based Automated Answer Sheet Evaluation System

## Project Overview
This project focuses on evaluating student answer sheets automatically using **Artificial Intelligence (AI)** and **Natural Language Processing (NLP)** techniques. The system analyzes studentsâ€™ answers, compares them with model answers, and assigns marks based on semantic similarity, keyword matching, and relevance. This reduces manual effort and ensures faster and unbiased evaluation.

---

## Problem Statement
Manual evaluation of answer sheets is time-consuming, inconsistent, and prone to human bias. With an increasing number of students, traditional evaluation methods become inefficient. There is a need for an **automated answer evaluation system** that can accurately and fairly assess descriptive answers using AI techniques.

---

## Objectives
- Automatically evaluate descriptive answers  
- Compare student answers with model answers  
- Assign marks based on content similarity  
- Provide fast and unbiased evaluation  
- Reduce workload of teachers  
- Develop a simple web-based interface  

---

## Technologies Used
- **Python 3.9+**
- **Streamlit** (Web Interface)
- **NLTK** (Text Processing)
- **Scikit-learn** (TF-IDF & Similarity)
- **Pandas** (Data Management)

---

## Applications
- Schools and colleges  
- Online examinations  
- Practice tests and assessments  

---

## Conclusion
This project demonstrates how AI and NLP can be effectively used to automate the evaluation of descriptive answer sheets, ensuring accuracy, fairness, and efficiency in the assessment process.
