 AI-Based Automated Answer Sheet Evaluation System
Project Overview

This project focuses on evaluating student answer sheets automatically using Artificial Intelligence and Natural Language Processing (NLP) techniques. The system analyzes studentsâ€™ answers, compares them with model answers, and assigns marks based on semantic similarity, keyword matching, and relevance. This reduces manual effort and ensures faster and unbiased evaluation.

Problem Statement

Manual evaluation of answer sheets is time-consuming, inconsistent, and prone to human bias. With increasing numbers of students, traditional evaluation methods are inefficient. There is a need for an automated answer evaluation system that can accurately and fairly assess descriptive answers using AI.

Objectives

Automatically evaluate descriptive answers

Compare student answers with model answers

Assign marks based on content similarity

Provide fast and unbiased evaluation

Reduce workload of teachers

Develop a simple web-based interface

Technologies Used

Python 3.9+

Streamlit (Web Interface)

NLTK (Text Processing)

Scikit-learn (TF-IDF & Similarity)

Pandas (Data Management)